{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0a6a7e",
   "metadata": {},
   "source": [
    "# Nexora RAG Customer Service Chatbot – Demo & Implementation Guide\n",
    "**Author:** Sujan Adhikari\n",
    "\n",
    "This interactive notebook walks through building a Retrieval‑Augmented Generation (RAG) customer‑service chatbot for **Nexora Pty Ltd** using **LangChain**, **Ollama Embeddings + Qwen3:1.7b**, and **ChromaDB**.  It covers:\n",
    "1. Data loading & preprocessing  \n",
    "2. Vector‑store creation  \n",
    "3. Simple intent recognition & entity extraction  \n",
    "4. RAG pipeline assembly  \n",
    "5. Lightweight Gradio web‑chat demo  \n",
    "6. (Optional) pointers for deployment & MLOps alignment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98e832",
   "metadata": {},
   "source": [
    "## 0  Environment & Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e821abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain-chroma langchain-ollama chromadb ollama gradio spacy pandas \n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82259e29",
   "metadata": {},
   "source": [
    "## 1  Imports & Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deaf0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, pandas as pd, csv\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "import spacy, gradio as gr\n",
    "from spacy.matcher import Matcher, PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf3a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# configure ollama model & embeddings\n",
    "MODEL = 'qwen3:1.7b'\n",
    "EMBEDDINGS_MODEL = \"mxbai-embed-large\"\n",
    "embeddings = OllamaEmbeddings(model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb07f0dd",
   "metadata": {},
   "source": [
    "## 2  Fix the faqs.csv dataset since there are questions separated by comma and not enclosed in quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b606c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(\"data/faqs.csv\")\n",
    "output_path = Path(\"data/faqs_cleaned.csv\")\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for row in reader:\n",
    "        if len(row) > 3:\n",
    "            # Fix rows with a comma in the question (merge columns until we have 3)\n",
    "            question_parts = row[:-2]  # Everything except last 2 fields\n",
    "            question = \",\".join(question_parts).strip()\n",
    "            answer = row[-2].strip()\n",
    "            category = row[-1].strip()\n",
    "            writer.writerow([question, answer, category])\n",
    "        else:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063982cb",
   "metadata": {},
   "source": [
    "## 2  Data Ingestion & Preprocessing: The Knowledge Foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12cd75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 136\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path('data')  # adjust if different\n",
    "products_path = DATA_DIR / 'products_occupation.json'\n",
    "faqs_path = DATA_DIR / 'faqs_cleaned.csv'\n",
    "\n",
    "# Load products\n",
    "with open(products_path, 'r', encoding='utf-8') as f:\n",
    "    products_data = json.load(f)['products']\n",
    "\n",
    "# Flatten products into plain‑text docs\n",
    "product_docs = []\n",
    "for p in products_data:\n",
    "    text = f\"\"\"\n",
    "    Product Name: {p['name']}\n",
    "    Description: {p['description']}\n",
    "    Target Industries: {', '.join(p['target_industries'])}\n",
    "    Coverage Options: {', '.join(p['coverage_options'])}\n",
    "    Premium Range: {p['premium_range']['min']}-{p['premium_range']['max']} {p['premium_range']['currency']}\n",
    "    Excess Range: {p['excess_range']['min']}-{p['excess_range']['max']} {p['excess_range']['currency']}\n",
    "    Key Features: {', '.join(p['key_features'])}\n",
    "    Exclusions: {', '.join(p['exclusions'])}\n",
    "    Unique Selling Points: {', '.join(p['unique_selling_points'])}\n",
    "    Required Documents: {', '.join(p['required_documents'])}\n",
    "    \"\"\".strip()\n",
    "    product_docs.append(Document(page_content=text, metadata={'type': 'product', 'name': p['name']}))\n",
    "\n",
    "\n",
    "# Load FAQs\n",
    "faqs_df = pd.read_csv(faqs_path, quotechar='\"')\n",
    "\n",
    "# ✅ Validate the structure of the CSV\n",
    "assert set(faqs_df.columns) == {'question', 'answer', 'category'}, \"Unexpected CSV format\"\n",
    "\n",
    "faq_docs = [\n",
    "    Document(\n",
    "        page_content=f\"Question: {row.question}\\nAnswer: {row.answer}\",\n",
    "        metadata={'type': 'faq', 'category': row.category}\n",
    "    )\n",
    "    for _, row in faqs_df.iterrows()\n",
    "]\n",
    "\n",
    "# Combine all documents\n",
    "documents = product_docs + faq_docs\n",
    "print(f'Total documents: {len(documents)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af9e0e",
   "metadata": {},
   "source": [
    "## 3  Create / Reload Chroma Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ed98ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built new vector store → nexora_chroma\n"
     ]
    }
   ],
   "source": [
    "# Set up vector store\n",
    "VECTOR_DIR = 'nexora_chroma'\n",
    "\n",
    "if Path(VECTOR_DIR).exists():\n",
    "    vector_store = Chroma(persist_directory=VECTOR_DIR, embedding_function=embeddings)\n",
    "    print('Loaded existing vector store.')\n",
    "else:\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=VECTOR_DIR\n",
    "    )\n",
    "    print('Built new vector store →', VECTOR_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376b544",
   "metadata": {},
   "source": [
    "## 4  Lightweight Intent Recognition & Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eac9086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claims\n",
      "{'products': ['professional indemnity'], 'industries': ['Professional Indemnity']}\n"
     ]
    }
   ],
   "source": [
    "INTENT_PATTERNS = {\n",
    "    'claims': r'\\b(claim|lodg(e|ing)|damage)\\b',\n",
    "    'coverage': r'\\b(cover(ed|age)|policy limit|exclusion|excess)\\b',\n",
    "    'products': r'\\bwhat is [A-Za-z ]+ insurance|types? of insurance\\b',\n",
    "    'pricing': r'\\b(cost|price|premium|fee)\\b',\n",
    "    'account': r'\\b(login|account|certificate of currency|policy documents|amend)\\b',\n",
    "}\n",
    "\n",
    "PRODUCT_NAMES = [p['name'].lower() for p in products_data]\n",
    "\n",
    "def classify_intent(query:str):\n",
    "    for intent, pattern in INTENT_PATTERNS.items():\n",
    "        if re.search(pattern, query, re.IGNORECASE):\n",
    "            return intent\n",
    "    return 'general'\n",
    "\n",
    "def extract_entities(query:str):\n",
    "    doc = nlp(query)\n",
    "    products = [p for p in PRODUCT_NAMES if p in query.lower()]\n",
    "    industries = [ent.text for ent in doc.ents if ent.label_=='ORG' or ent.label_=='NORP']\n",
    "    return {'products': products, 'industries': industries}\n",
    "\n",
    "print(classify_intent('How do I lodge a claim?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa37e9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'products': ['professional indemnity'], 'industries': ['Professional Indemnity']}\n"
     ]
    }
   ],
   "source": [
    "print(extract_entities('Do you cover Architecture firms for Professional Indemnity?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8562e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general\n"
     ]
    }
   ],
   "source": [
    "print(classify_intent('How do I update my payment details?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92bc02",
   "metadata": {},
   "source": [
    "## 5  Build Retrieval‑Augmented QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=MODEL, temperature=0, num_ctx=10000)\n",
    "\n",
    "prompt_template = (\n",
    "    \"You are NexoraBot, a helpful and knowledgeable customer-service assistant for an Australian SME insurance broker. \"\n",
    "    \"Use ONLY the provided context to answer. If unsure, say you don't know but can escalate to a human agent. \"\n",
    "    \"Answer in a friendly, concise manner and, where relevant, suggest next steps inside Nexora's platform.\\n\"\n",
    "    \"/no_think\\n\"\n",
    "    \"If the context does NOT contain enough information, clearly state that you cannot answer the question with the current information and suggest they contact a human agent at Nexora for more specialized advice (e.g., I don't have specific details on that. For more specialized advice, please contact a Nexora agent at support@nexora.com.au or call us.)\\n\\n\"\n",
    "    \"### Context\\n{context}\\n\\n### Question\\n{question}\\n\\n### Answer\\n\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=vector_store.as_retriever(search_kwargs={'k':4}),\n",
    "    chain_type_kwargs={'prompt': prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5629161",
   "metadata": {},
   "source": [
    "### Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99b2f4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Professional Indemny covers legal liability for financial loss arising from professional errors or omissions. \n",
      "\n",
      "Next step: If you need further details or want to check if your policy covers this, please contact a Nexora agent at support@nexora.com.au or call us.<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Professional Indemny covers legal liability for financial loss arising from professional errors or omissions. \n",
      "\n",
      "Next step: If you need further details or want to check if your policy covers this, please contact a Nexora agent at support@nexora.com.au or call us.\n"
     ]
    }
   ],
   "source": [
    "question = 'What does Professional Indemnity cover?'\n",
    "print(rag_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78eda906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "To change your password, follow these steps:\n",
      "\n",
      "1. Log in to your Nexora account.\n",
      "2. Click on the \"Forgot Password\" link on the login page.\n",
      "3. Enter your email address.\n",
      "4. Click \"Send Password Reset Link.\"\n",
      "5. Follow the instructions to set a new password.\n",
      "\n",
      "If you need further assistance, contact a Nexora agent at support@nexora.com.au or call us.{'query': 'How do I change my password?', 'result': '<think>\\n\\n</think>\\n\\nTo change your password, follow these steps:\\n\\n1. Log in to your Nexora account.\\n2. Click on the \"Forgot Password\" link on the login page.\\n3. Enter your email address.\\n4. Click \"Send Password Reset Link.\"\\n5. Follow the instructions to set a new password.\\n\\nIf you need further assistance, contact a Nexora agent at support@nexora.com.au or call us.'}\n"
     ]
    }
   ],
   "source": [
    "question = 'How do I change my password?'\n",
    "print(rag_chain.invoke({'query': question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75dd9d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "To update your personal details, log in to your Nexora account and navigate to the \"Profile\" section. From there, you can edit your personal information such as your name, email address, and contact details. If you need further assistance, contact a Nexora agent at support@nexora.com.au.{'query': 'How do I update my personal details?', 'result': '<think>\\n\\n</think>\\n\\nTo update your personal details, log in to your Nexora account and navigate to the \"Profile\" section. From there, you can edit your personal information such as your name, email address, and contact details. If you need further assistance, contact a Nexora agent at support@nexora.com.au.'}\n"
     ]
    }
   ],
   "source": [
    "question = 'How do I update my personal details?'\n",
    "print(rag_chain.invoke({'query': question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f4540",
   "metadata": {},
   "source": [
    "## 6  Gradio Web Chat Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b4697ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_function(message, history):\n",
    "    intent = classify_intent(message)\n",
    "    entities = extract_entities(message)\n",
    "\n",
    "    result = rag_chain.invoke(message)\n",
    "    answer = result[\"result\"]\n",
    "\n",
    "    meta_note = f\"\\n\\n_Bot note: intent={intent}, entities={entities}_\"\n",
    "    return answer + meta_note\n",
    "\n",
    "with gr.Blocks(title='Nexora Chatbot Demo') as demo:\n",
    "    gr.Markdown('# Nexora Insurance Chatbot')\n",
    "    chatbot = gr.Chatbot(type='messages')\n",
    "    msg = gr.Textbox(placeholder='Ask a question about your policy…', label='Your message')\n",
    "    send = gr.Button('Send')\n",
    "    state = gr.State([])  # List[Tuple[str, str]]\n",
    "\n",
    "    def respond(user_message, chat_history):\n",
    "        bot_reply = chat_function(user_message, chat_history)\n",
    "        chat_history.append((user_message, bot_reply))\n",
    "        return '', chat_history, chat_history\n",
    "\n",
    "    send.click(respond, [msg, state], [msg, chatbot, state])\n",
    "\n",
    "# To launch the interface inside notebook use demo.launch(debug=True)\n",
    "# Or from CLI: `python -m gradio app.py` if saved separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74c9214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "To update your personal details, log in to your Nexora account and navigate to the \"Profile\" section. From there, you can edit your personal information such as your name, email, and contact details. If you need further assistance, contact a Nexora agent at support@nexora.com.au."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zerad\\Desktop\\NexoraGuard\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\zerad\\Desktop\\NexoraGuard\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\zerad\\Desktop\\NexoraGuard\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2156, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\zerad\\Desktop\\NexoraGuard\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1940, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\zerad\\Desktop\\NexoraGuard\\.venv\\Lib\\site-packages\\gradio\\components\\chatbot.py\", line 629, in postprocess\n",
      "    self._check_format(value, \"messages\")\n",
      "  File \"c:\\Users\\zerad\\Desktop\\NexoraGuard\\.venv\\Lib\\site-packages\\gradio\\components\\chatbot.py\", line 419, in _check_format\n",
      "    raise Error(\n",
      "gradio.exceptions.Error: \"Data incompatible with messages format. Each message should be a dictionary with 'role' and 'content' keys or a ChatMessage object.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655ad65",
   "metadata": {},
   "source": [
    "## 7  Deployment & Next Steps (Conceptual)\n",
    "* **FastAPI + Uvicorn** wrapper to expose `chat_function` as `/chat` endpoint.  \n",
    "* **Docker** containerization with Ollama serving model weights locally.  \n",
    "* **CI/CD** via GitHub Actions → build, push image to GHCR, deploy to Azure Container Apps.  \n",
    "* **Monitoring**: Prometheus + Grafana for latency, Chroma vector‑store health; OpenTelemetry traces for LLM calls.  \n",
    "* **Fine‑Tuning**: see `finetune_plan.md` (not included) for leveraging annotated conversations to supervise‑fine‑tune Llama‑3 using QLoRA.\n",
    "\n",
    "---\n",
    "**Enjoy experimenting with your Nexora chatbot!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
